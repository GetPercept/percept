# Contributing to Percept

Welcome! Percept gives AI agents ears â€” ambient voice intelligence for OpenClaw and beyond. ğŸ¦

## Quick Links

- **GitHub:** https://github.com/GetPercept/percept
- **X/Twitter:** [@getpercept](https://x.com/getpercept)
- **OpenClaw Discord:** https://discord.gg/qkhbAGHRBT

## Maintainers

- **David Emanuel** - Creator
  - GitHub: [@davidemanuelDEV](https://github.com/davidemanuelDEV) Â· X: [@jarv31168](https://x.com/jarv31168)

## How to Contribute

1. **Bugs & small fixes** â†’ Open a PR directly
2. **New features / architecture changes** â†’ Open a GitHub Issue or Discussion first
3. **Skills** â†’ Add or improve skills in `skills/`
4. **Docs** â†’ Always welcome, no discussion needed
5. **Questions** â†’ Open an issue or ask in OpenClaw Discord

## Before You PR

- Test locally with your Percept + OpenClaw setup
- Run tests: `cd percept && python -m pytest tests/ -v`
- Keep PRs focused â€” one thing per PR
- Describe what & why in the PR description

## Development Setup

```bash
# Clone
git clone https://github.com/GetPercept/percept.git
cd percept

# Create virtual environment
python3.11 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run tests
python -m pytest tests/ -v

# Start the receiver
PYTHONPATH=. python -m uvicorn src.receiver:app --host 0.0.0.0 --port 8900

# Start the dashboard
PYTHONPATH=. python -m uvicorn src.dashboard:app --host 0.0.0.0 --port 8960
```

## Project Structure

```
percept/
â”œâ”€â”€ src/                    # Core source code
â”‚   â”œâ”€â”€ receiver.py         # FastAPI webhook receiver
â”‚   â”œâ”€â”€ transcriber.py      # Audio transcription (Whisper, NVIDIA, cloud)
â”‚   â”œâ”€â”€ intent_parser.py    # Two-tier intent parsing (regex + LLM)
â”‚   â”œâ”€â”€ action_dispatcher.py # Voice command routing to OpenClaw
â”‚   â”œâ”€â”€ speaker_manager.py  # Speaker identification & authorization
â”‚   â”œâ”€â”€ entity_extractor.py # Entity extraction from conversations
â”‚   â”œâ”€â”€ context_engine.py   # Context Intelligence Layer
â”‚   â”œâ”€â”€ database.py         # SQLite persistence (11 tables, FTS5)
â”‚   â”œâ”€â”€ vector_store.py     # LanceDB semantic search
â”‚   â”œâ”€â”€ flush_manager.py    # Transcript buffering & wake word detection
â”‚   â”œâ”€â”€ summary_manager.py  # Conversation summarization
â”‚   â”œâ”€â”€ dashboard.py        # Real-time monitoring dashboard
â”‚   â””â”€â”€ cli.py              # Command-line interface
â”œâ”€â”€ skills/                 # ClawHub skill definitions
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ data/                   # Local data (gitignored)
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ landing/                # Landing page
```

## Areas We Need Help

### High Priority
- **Hardware integrations** â€” More wearable devices beyond Omi and Apple Watch
- **Transcriber backends** â€” Deepgram, AssemblyAI, Azure Speech integrations
- **Speaker diarization** â€” pyannote voice embeddings for automatic speaker ID
- **Language support** â€” Non-English wake words, multilingual transcription

### Medium Priority
- **Dashboard improvements** â€” Better visualizations, entity graph rendering
- **Privacy features** â€” On-device encryption, selective redaction
- **Agent framework integrations** â€” Beyond OpenClaw (LangChain, CrewAI, AutoGen)
- **Performance** â€” Optimize SQLite queries, reduce memory footprint

### Always Welcome
- Bug fixes
- Documentation improvements
- Test coverage
- Code cleanup and refactoring

## AI-Assisted PRs Welcome ğŸ¤–

Built with Codex, Claude, or other AI tools? Great â€” just mark it.

Include in your PR:
- [ ] Mark as AI-assisted in the PR title or description
- [ ] Note the degree of testing
- [ ] Confirm you understand what the code does

AI PRs are first-class citizens. We just want transparency.

## Code Style

- Python 3.9+ compatible (no union types with `|`, use `Optional`, `List`, `Dict`)
- Type hints on all public functions
- Docstrings on all modules and public functions
- SQLite compatible types (no PostgreSQL-specific features)
- Async where appropriate (FastAPI handlers, external API calls)

## Commit Messages

Use conventional commits:
```
feat: add Deepgram transcriber backend
fix: handle empty transcript segments
docs: update setup instructions for Apple Watch
test: add intent parser edge cases
```

## Security

- **Never commit API keys, tokens, or credentials**
- **Audio data stays local** â€” don't add features that upload raw audio
- **Speaker authorization is a security boundary** â€” treat it carefully
- Report vulnerabilities via GitHub Issues (private) or email hello@getpercept.ai

## First 50 Contributors ğŸ

The first 50 people who contribute meaningfully get **lifetime Pro access** to the hosted Percept API when it launches. Star the repo, submit a PR, or file a detailed bug report â€” anything that helps counts.

## License

MIT â€” free forever. See [LICENSE](LICENSE).
